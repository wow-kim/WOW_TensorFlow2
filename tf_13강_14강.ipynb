{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_13강_14강.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmdA88lrurtH"
      },
      "source": [
        "# 13강\r\n",
        "- Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmzfMg8v134K",
        "outputId": "89ce5e71-90c6-4284-86dd-b8dd5147b9fc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "train_ds = tfds.load(name = 'mnist',\r\n",
        "                     shuffle_files=True,\r\n",
        "                     as_supervised=True,\r\n",
        "                     split='train',\r\n",
        "                     batch_size=4)\r\n",
        "\r\n",
        "for images, labels in train_ds:\r\n",
        "  print(images.shape)\r\n",
        "  print(images.dtype)\r\n",
        "\r\n",
        "  print(tf.reduce_max(images)) # 반드시 scaling해주어야함, weight의 변동이 너무커지기 때문.\r\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 28, 28, 1)\n",
            "<dtype: 'uint8'>\n",
            "tf.Tensor(255, shape=(), dtype=uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE2PL5sz4bHr",
        "outputId": "8f088901-b8e3-4e77-9a4e-c0ecde090116"
      },
      "source": [
        "t1 = tf.constant([1, 2, 3, 4, 5])\r\n",
        "print(t1.dtype)\r\n",
        "t2 = tf.cast(t1, tf.float32) # casting\r\n",
        "print(t2.dtype)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dtype: 'int32'>\n",
            "<dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkdzAb1748Sk",
        "outputId": "c279b22f-4b5c-4acb-9aac-4bba3219dc97"
      },
      "source": [
        "# 0부터 1까지의 값을 갖도록\r\n",
        "# float32형식을 갖도록\r\n",
        "# 함수를 이용해 한번에 해줄 수 있었다!\r\n",
        "def standardization(images, labels):\r\n",
        "  images = tf.cast(images, tf.float32) / 255.\r\n",
        "  return [images, labels]\r\n",
        "\r\n",
        "train_ds, test_ds = tfds.load(name = 'mnist',\r\n",
        "                     shuffle_files=True,\r\n",
        "                     as_supervised=True,\r\n",
        "                     split=['train','test'],\r\n",
        "                     batch_size=4)\r\n",
        "\r\n",
        "train_ds_iter = iter(train_ds)\r\n",
        "images, labels = next(train_ds_iter)\r\n",
        "print(images.dtype, tf.reduce_max(images))\r\n",
        "\r\n",
        "# 텐서에도 map 가능\r\n",
        "train_ds = train_ds.map(standardization)\r\n",
        "test_ds = test_ds.map(standardization)\r\n",
        "\r\n",
        "train_ds_iter = iter(train_ds)\r\n",
        "images, labels = next(train_ds_iter)\r\n",
        "print(images.dtype, tf.reduce_max(images))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dtype: 'uint8'> tf.Tensor(255, shape=(), dtype=uint8)\n",
            "<dtype: 'float32'> tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttuJ1VzA6Upv",
        "outputId": "456339e5-759a-49b7-8dbc-de7c873134d9"
      },
      "source": [
        "def mnist_data_loader():\r\n",
        "  def standardization(images, labels):\r\n",
        "    images = tf.cast(images, tf.float32) / 255.\r\n",
        "    return [images, labels]\r\n",
        "\r\n",
        "  train_ds, test_ds = tfds.load(name = 'mnist',\r\n",
        "                       shuffle_files=True,\r\n",
        "                       as_supervised=True,\r\n",
        "                       split=['train','test'],\r\n",
        "                       batch_size=4)\r\n",
        "  \r\n",
        "  train_ds = train_ds.map(standardization)\r\n",
        "  test_ds = test_ds.map(standardization)\r\n",
        "  return train_ds, test_ds\r\n",
        "\r\n",
        "train_ds, test_ds = mnist_data_loader()\r\n",
        "print(train_ds)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJl563NP60oL"
      },
      "source": [
        "# 14강\r\n",
        "- Losses and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GY6Ky8k6zzz",
        "outputId": "8efe718b-755e-41d6-bc4c-0bc30d2122e3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\r\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy, SparseCategoricalAccuracy\r\n",
        "\r\n",
        "loss_object = BinaryCrossentropy()\r\n",
        "\r\n",
        "predictions = np.array([0.3]).reshape(-1, 1)\r\n",
        "labels = np.array([1])\r\n",
        "\r\n",
        "loss = loss_object(labels, predictions)\r\n",
        "loss_manual = -1*((labels*np.log(predictions)) + \\\r\n",
        "                  (1-labels)*np.log(1-predictions))\r\n",
        "print(loss.numpy())\r\n",
        "print(loss_manual)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2039724588394165\n",
            "[[1.2039728]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-OkKMH18ph4",
        "outputId": "1b4b8f76-2b9e-4691-c9f2-b7efac37f96f"
      },
      "source": [
        "# label 이 vector형식([0, 1])인 경우\r\n",
        "predictions = np.array([0.3, 0.6]).reshape(-1, 1)\r\n",
        "labels = np.array([1, 0]).reshape(-1, 1)\r\n",
        "\r\n",
        "loss = loss_object(labels, predictions)\r\n",
        "loss_manual = -1*((labels*np.log(predictions)) + \\\r\n",
        "                  (1-labels)*np.log(1-predictions))\r\n",
        "loss_manual = np.mean(loss_manual)\r\n",
        "\r\n",
        "print(loss.numpy())\r\n",
        "print(loss_manual)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0601314306259155\n",
            "1.0601317681000455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px77ljoF9quB",
        "outputId": "e6f439f5-6f7b-4cb9-ed55-3d285f5b07a5"
      },
      "source": [
        "predictions = np.array([[0.3, 0.7], [0.4, 0.6], [0.1, 0.9]])\r\n",
        "labels = np.array([[0,1], [1,0], [1,0]])\r\n",
        "\r\n",
        "loss = loss_object(labels, predictions)\r\n",
        "loss_manual = -1*labels*np.log(predictions)\r\n",
        "loss_manual = np.sum(loss_manual, axis=1)\r\n",
        "loss_manual = np.mean(loss_manual)\r\n",
        "\r\n",
        "print(loss.numpy())\r\n",
        "print(loss_manual)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1918498277664185\n",
            "1.1918502562689777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CWHrviM-g-s",
        "outputId": "0c6420f9-9ddc-49ad-cf67-3332dbe9f921"
      },
      "source": [
        "loss_object = CategoricalCrossentropy()\r\n",
        "\r\n",
        "predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\r\n",
        "labels = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\r\n",
        "\r\n",
        "print(predictions)\r\n",
        "print(labels)\r\n",
        "\r\n",
        "loss = loss_object(labels, predictions)\r\n",
        "loss_manual = -1*labels*np.log(predictions)\r\n",
        "loss_manual = np.sum(loss_manual, axis=1)\r\n",
        "loss_manual = np.mean(loss_manual)\r\n",
        "\r\n",
        "print(loss.numpy())\r\n",
        "print(loss_manual)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.1 0.7]\n",
            " [0.4 0.3 0.3]\n",
            " [0.1 0.8 0.1]]\n",
            "[[0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]]\n",
            "1.2877442836761475\n",
            "1.2877442804195713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSfz-66Z_kkL",
        "outputId": "7b08f612-2e9f-4b79-827f-67d39b86d0f7"
      },
      "source": [
        "loss_object = SparseCategoricalCrossentropy()\r\n",
        "\r\n",
        "predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\r\n",
        "labels = np.array([2, 1, 0])\r\n",
        "\r\n",
        "loss = loss_object(tf.constant(labels), tf.constant(predictions))\r\n",
        "\r\n",
        "ce_loss =0\r\n",
        "for data_idx in range(len(labels)):\r\n",
        "  prediction = predictions[data_idx]\r\n",
        "  label = labels[data_idx]\r\n",
        "\r\n",
        "  t_prediction = prediction[label]\r\n",
        "  ce_loss += -1*np.log(t_prediction)\r\n",
        "ce_loss = ce_loss / len(labels)\r\n",
        "\r\n",
        "print(loss.numpy())\r\n",
        "print(ce_loss)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2877442836761475\n",
            "1.2877442804195713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU4xqsyiAvmE",
        "outputId": "061d3af0-26b9-4706-bb33-c3c18214ba60"
      },
      "source": [
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "train_ds = tfds.load(name = 'mnist',\r\n",
        "                     shuffle_files=True,\r\n",
        "                     as_supervised=True,\r\n",
        "                     split='train')\r\n",
        "\r\n",
        "train_ds = train_ds.batch(8)\r\n",
        "\r\n",
        "train_ds_iter = iter(train_ds)\r\n",
        "images, labels = next(train_ds_iter) \r\n",
        "print(labels) # Sparse를 써야겠구나!"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([4 1 0 7 1 8 2 7], shape=(8,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9IzTVZaBQkJ",
        "outputId": "7140e3f5-0169-47cf-9108-44a14928c4e9"
      },
      "source": [
        "metric = CategoricalAccuracy()\r\n",
        "\r\n",
        "predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\r\n",
        "labels = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\r\n",
        "\r\n",
        "acc = metric(labels, predictions)\r\n",
        "\r\n",
        "print(acc*100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(33.333336, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "hWFF4Hq8Bhub",
        "outputId": "2cd1ff77-c528-428e-b299-10628b1f3759"
      },
      "source": [
        "metric = SparseCategoricalAccuracy\r\n",
        "\r\n",
        "predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\r\n",
        "labels = np.array([2, 1, 0])\r\n",
        "\r\n",
        "acc = metric(labels, predictions)\r\n",
        "print(acc*100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-469db6954073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dtype)\u001b[0m\n\u001b[1;32m    830\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     super(SparseCategoricalAccuracy, self).__init__(\n\u001b[0;32m--> 832\u001b[0;31m         sparse_categorical_accuracy, name, dtype=dtype)\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeanMetricWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dtype)\u001b[0m\n\u001b[1;32m    487\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     super(Mean, self).__init__(\n\u001b[0;32m--> 489\u001b[0;31m         reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reduction, name, dtype)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     self.total = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# All metric layers are stateful.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_set_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     self._activity_regularizer = regularizers.get(\n\u001b[1;32m    367\u001b[0m         kwargs.pop('activity_regularizer', None))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_init_set_name\u001b[0;34m(self, name, zero_based)\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_set_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m       self._name = backend.unique_object_name(\n\u001b[1;32m   2478\u001b[0m           \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_snake_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    }
  ]
}