{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_16강.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMidwz6VJCwY76/fTmlLV/v"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_NllWvPgQAv2"},"source":["# 16강\r\n","- Mnist Classification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHmRaXrOQF2J","outputId":"cf938d26-15aa-4d1e-cb78-ba5935a150e7"},"source":["import tensorflow as tf\r\n","import tensorflow_datasets as tfds\r\n","\r\n","from tensorflow.keras.models import Sequential, Model\r\n","from tensorflow.keras.layers import Flatten, Dense, Activation\r\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\r\n","from tensorflow.keras.optimizers import SGD, Adam\r\n","\r\n","from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","from termcolor import colored\r\n","\r\n","def get_mnist_ds():\r\n","  (train_validation_ds, test_ds), ds_info = tfds.load(name = 'mnist',\r\n","                                                      shuffle_files = True,\r\n","                                                      as_supervised = True,\r\n","                                                      split = ['train', 'test'],\r\n","                                                      with_info = True\r\n","                                                      )\r\n","  n_train_validation = ds_info.splits['train'].num_examples\r\n","\r\n","  train_ratio = 0.8\r\n","  n_train = int(n_train_validation * train_ratio)\r\n","  n_validation = n_train_validation - n_train\r\n","\r\n","  train_ds = train_validation_ds.take(n_train)\r\n","  remaining_ds = train_validation_ds.skip(n_train)\r\n","  validation_ds = remaining_ds.take(n_validation)\r\n","\r\n","  return train_ds, validation_ds, test_ds\r\n","\r\n","def standardization(train_batch_size, test_batch_size):\r\n","  global train_ds, validation_ds, test_ds\r\n","\r\n","  def stnd(images, labels):\r\n","    images = tf.cast(images, tf.float32) / 255.\r\n","    return [images, labels]\r\n","\r\n","  train_ds = train_ds.map(stnd).shuffle(1000).batch(train_batch_size)\r\n","  validation_ds = validation_ds.map(stnd).batch(test_batch_size)\r\n","  test_ds = test_ds.map(stnd).batch(test_batch_size)\r\n","\r\n","class MNIST_Classifier(Model):\r\n","  def __init__(self):\r\n","    super(MNIST_Classifier, self).__init__()\r\n","\r\n","    self.Flatten = Flatten()\r\n","    self.d1 = Dense(64, activation = 'relu')\r\n","    self.d2 = Dense(10, activation = 'softmax')\r\n","\r\n","  def call(self, x):\r\n","    x = self.Flatten(x)\r\n","    x = self.d1(x)\r\n","    x = self.d2(x)\r\n","    return x\r\n","\r\n","def load_metrics():\r\n","  global train_loss, train_acc\r\n","  global validation_loss, validation_acc\r\n","  global test_loss, test_acc\r\n","\r\n","  train_loss = Mean()\r\n","  validation_loss = Mean()\r\n","  test_loss = Mean()\r\n","\r\n","  train_acc = SparseCategoricalAccuracy()\r\n","  validation_acc = SparseCategoricalAccuracy()\r\n","  test_acc = SparseCategoricalAccuracy()\r\n","\r\n","@tf.function\r\n","def trainer():\r\n","  global train_ds, model, loss_object, optimizer\r\n","  global train_loss, train_acc\r\n","\r\n","  for images, labels in train_ds:\r\n","    with tf.GradientTape() as tape:\r\n","      predictions = model(images)\r\n","      loss = loss_object(labels, predictions)\r\n","\r\n","    gradients = tape.gradient(loss, model.trainable_variables)\r\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n","\r\n","    train_loss(loss)\r\n","    train_acc(labels, predictions)\r\n","\r\n","@tf.function\r\n","def validation():\r\n","  global validation_ds, model, loss_object\r\n","  global validation_loss, validation_acc\r\n","\r\n","  for images, labels in validation_ds:\r\n","    predictions = model(images)\r\n","    loss = loss_object(labels, predictions)\r\n","\r\n","    validation_loss(loss)\r\n","    validation_acc(labels, predictions)\r\n","\r\n","#@tf.function -> print문이 있으면 써주지 않습니다\r\n","def tester():\r\n","  global test_ds, model, loss_object\r\n","  global test_loss, test_acc\r\n","\r\n","  for images, labels in test_ds:\r\n","    predictions = model(images)\r\n","    loss = loss_object(labels, predictions)\r\n","\r\n","    test_loss(loss)\r\n","    test_acc(labels, predictions)\r\n","  \r\n","  template ='Test Loss: {:.4f}\\t Test Accuracy: {:.2f}%\\n'\r\n","  print(template.format(test_loss.result(), test_acc.result()*100))\r\n","\r\n","\r\n","def train_report():\r\n","  global epoch\r\n","  global train_loss, train_loss\r\n","  global vaidation_loss, validation_acc\r\n","\r\n","  print(colored('Epoch: ', 'red', 'on_white'), epoch +1)\r\n","  template ='Train Loss: {:.4f}\\t Train Accuracy: {:.2f}%\\n \\t Validation Loss: {:.4f}\\t Validation Accuracy: {:.2f}%\\n'\r\n","  print(template.format(train_loss.result(), train_acc.result()*100,\r\n","                        validation_loss.result(), validation_acc.result()*100))\r\n","  \r\n","  train_loss.reset_states()\r\n","  train_acc.reset_states()\r\n","  validation_loss.reset_states()\r\n","  validation_acc.reset_states()\r\n","\r\n","EPOCHS = 10\r\n","LR = 0.001\r\n","train_batch_size = 16\r\n","test_batch_size = 32\r\n","\r\n","train_ds, validation_ds, test_dst = get_mnist_ds()\r\n","standardization(train_batch_size, test_batch_size)\r\n","\r\n","model = MNIST_Classifier()\r\n","loss_object = SparseCategoricalCrossentropy()\r\n","optimizer = SGD(learning_rate = LR)\r\n","\r\n","load_metrics()\r\n","\r\n","for epoch in range(EPOCHS):\r\n","  trainer()\r\n","  validation()\r\n","  train_report()\r\n","\r\n","tester()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[47m\u001b[31mEpoch: \u001b[0m 1\n","Train Loss: 1.5173\t Train Accuracy: 60.75%\n"," \t Validation Loss: 0.9592\t Validation Accuracy: 78.58%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 2\n","Train Loss: 0.7531\t Train Accuracy: 82.82%\n"," \t Validation Loss: 0.6264\t Validation Accuracy: 85.02%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 3\n","Train Loss: 0.5570\t Train Accuracy: 86.31%\n"," \t Validation Loss: 0.5110\t Validation Accuracy: 86.89%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 4\n","Train Loss: 0.4743\t Train Accuracy: 87.72%\n"," \t Validation Loss: 0.4522\t Validation Accuracy: 88.12%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 5\n","Train Loss: 0.4276\t Train Accuracy: 88.65%\n"," \t Validation Loss: 0.4158\t Validation Accuracy: 88.92%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 6\n","Train Loss: 0.3970\t Train Accuracy: 89.21%\n"," \t Validation Loss: 0.3909\t Validation Accuracy: 89.42%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 7\n","Train Loss: 0.3751\t Train Accuracy: 89.65%\n"," \t Validation Loss: 0.3723\t Validation Accuracy: 89.78%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 8\n","Train Loss: 0.3582\t Train Accuracy: 90.07%\n"," \t Validation Loss: 0.3576\t Validation Accuracy: 90.17%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 9\n","Train Loss: 0.3445\t Train Accuracy: 90.40%\n"," \t Validation Loss: 0.3458\t Validation Accuracy: 90.41%\n","\n","\u001b[47m\u001b[31mEpoch: \u001b[0m 10\n","Train Loss: 0.3330\t Train Accuracy: 90.66%\n"," \t Validation Loss: 0.3356\t Validation Accuracy: 90.63%\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XkqQyi53U0zX"},"source":[""],"execution_count":null,"outputs":[]}]}